## AI-DRIVEN ACOUSTIC SURVEILLANCE SYSTEM 
The development of an AI-driven acoustic surveillance system, designed to detect distress signals like screams in real time, ensuring faster emergency responses and enhancing public safety in urban areas.
## About
An AI-driven acoustic surveillance system leverages advanced audio processing techniques, such as MFCCs, spectrograms, and STFT, along with machine learning models like CNNs, SVMs, and LSTMs to detect distress signals, such as screams, in real-time. The system automates noise filtering, feature extraction, and classification, generating real-time alerts with metadata (location, timestamp) sent to authorities for immediate response. Designed for scalability and integration with existing infrastructure, it operates efficiently in noisy environments, ensuring enhanced public safety, faster emergency responses, and proactive urban security monitoring.

## Features
1.Real-Time Audio Detection
2.Noise Filtering
3.Advanced Feature Extraction
4.Machine Learning Classification
5.Real-Time Alerts
6.Scalability and Integration
7.Event Logging and Database Storage
8.Report Generation
9.Adaptability in Noisy Environments
10.Cost-Effective and Automated

## Requirements
**Operating System:** Requires a 64-bit OS (Windows 10, Ubuntu, or macOS) for compatibility with audio processing and deep learning frameworks.
**Development Environment:** Python 3.6 or later is necessary for coding the acoustic surveillance system and implementing machine learning models.
**Deep Learning Frameworks:** TensorFlow or PyTorch for model training and classification tasks.
**Audio Processing Libraries:** Librosa for audio feature extraction (MFCCs, spectrograms, STFT), and pyaudio for real-time audio capture and streaming.
**Machine Learning Libraries:** scikit-learn for implementing traditional classifiers like SVM and Random Forest.
**Version Control:** Git for version control to manage the project and facilitate collaborative development.
**IDE:** VSCode or PyCharm for coding, debugging, and integrating version control.
**Additional Dependencies:**Includes TensorFlow, PyTorch, scikit-learn, librosa, pyaudio, numpy, and matplotlib for training models, real-time audio processing, and data visualization.

## System Architecture

![Screenshot 2024-12-13 160559](https://github.com/user-attachments/assets/14d16df3-04aa-4f6d-aa38-ba454c3bd359)

## Output

#### Output1 - SAMPLE OUTPUT :

![Screenshot 2024-12-14 094832](https://github.com/user-attachments/assets/c0f5899b-c213-42fc-8413-5016e0f18ecf)

#### Output2 - REPORT GENERATING:

![Screenshot 2024-12-13 220554](https://github.com/user-attachments/assets/6be54a06-858e-4ff6-b658-e112b5e5a8e4)

Metrics : 
Precision : 94
Accuracy : 92
Recall :92
F1 score :94

Detection Accuracy: 0.92%

## Results and Impact:

The AI-driven Acoustic Surveillance System enhances public safety by providing a reliable tool for real-time distress signal detection, such as screams, in urban environments. Its integration of advanced audio processing and machine learning demonstrates its potential for automated and efficient surveillance solutions.

This project serves as a foundation for future advancements in urban security systems, including smart city integration and proactive crime prevention. It contributes to building safer and more responsive urban spaces, ensuring timely emergency responses and fostering a secure environment for communities.
## Articles published / References:
1.Shaghaghian, S., Feng, L. Y., Jafarpour, B., & Pogrebnyakov, N. (2020). Customizing Contextualized Language Models for Legal Document Reviews. IEEE International Conference on Big Data (Big Data), 2139-2148. doi: 10.1109/BigData50022.2020.9378201.

2.Piczak, K. J. (2015). Environmental Sound Classification with Convolutional Neural Networks. Proceedings of the 23rd ACM International Conference on Multimedia, 611-614. doi: 10.1145/2733373.2806352.

3.Ellis, D. P. W., & Lee, K. (2004). Features and Classifiers for the Detection of Human Distress Sounds. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 485-488.
