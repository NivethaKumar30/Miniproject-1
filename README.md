## AI-DRIVEN ACOUSTIC SURVEILLANCE SYSTEM 
The development of an AI-driven acoustic surveillance system, designed to detect distress signals like screams in real time, ensuring faster emergency responses and enhancing public safety in

## About
An AI-driven acoustic surveillance system leverages advanced audio processing techniques, such as MFCCs, spectrograms, and STFT, along with machine learning models like CNNs, SVMs, and LSTMs to detect distress signals, such as screams, in real-time. The system automates noise filtering, feature extraction, and classification, generating real-time alerts with metadata (location, timestamp) sent to authorities for immediate response. Designed for scalability and integration with existing infrastructure, it operates efficiently in noisy environments, ensuring enhanced public safety, faster emergency responses, and proactive urban security monitoring.
## Features
 1.Real-Time Audio Detection
 2. Noise Filtering
 3.Advanced Feature Extraction
 4. Machine Learning Classification
 5. Real-Time Alerts
 6.Scalability and Integration
 7. Event Logging and Database Storage
 8.Report Generation
 9. Adaptability in Noisy Environments
 10.Cost-Effective and Automated

## Requirements

1.Microphones: High-quality omnidirectional microphones for capturing audio.
2.Edge Computing Device: Devices like NVIDIA Jetson Nano or Raspberry Pi 4 for real-time processing.
3.Graphics Processing Unit (GPU): NVIDIA RTX 3080 or equivalent for machine learning model inference.
4.Storage: Solid-State Drives (SSDs) for storing audio data and classification results.
5.Programming Language: Python for audio processing and machine learning.
6.Audio Libraries: librosa and pyaudio for feature extraction and real-time audio capture.
7.Machine Learning Frameworks: TensorFlow, PyTorch for training and deploying models.
8.Database: MongoDB for unstructured data and PostgreSQL for structured event metadata.
9.Alerting Tools: Twilio or Firebase Cloud Messaging for real-time notifications.
10.Web Development Tools: Flask or Django for backend development.

## System Architecture:

![Screenshot 2024-12-13 160559](https://github.com/user-attachments/assets/4cce7dd5-06f2-4d90-8a58-16ef04d6990c)

## Output

#### Output1 - SAMPLE OUTPUT
![Screenshot 2024-12-14 094832](https://github.com/user-attachments/assets/03258077-cba9-42c1-b254-c3c22828be9e)


#### Output2 - ALERT TO AUTHORIES:

![Screenshot 2024-12-13 220554](https://github.com/user-attachments/assets/0500f96b-9995-4670-8503-8eb6dedb0091)


Detection Accuracy: 0.79%


## Results and Impact
The AI-driven Acoustic Surveillance System enhances public safety by providing a reliable tool for real-time distress signal detection, such as screams, in urban environments. Its integration of advanced audio processing and machine learning demonstrates its potential for automated and efficient surveillance solutions.

This project serves as a foundation for future advancements in urban security systems, including smart city integration and proactive crime prevention. It contributes to building safer and more responsive urban spaces, ensuring timely emergency responses and fostering a secure environment for communities.t.

## Articles published / References
1.Shaghaghian, S., Feng, L. Y., Jafarpour, B., & Pogrebnyakov, N. (2020). Customizing Contextualized Language Models for Legal Document Reviews. IEEE International Conference on Big Data (Big Data), 2139-2148. doi: 10.1109/BigData50022.2020.9378201.
2.Piczak, K. J. (2015). Environmental Sound Classification with Convolutional Neural Networks. Proceedings of the 23rd ACM International Conference on Multimedia, 611-614. doi: 10.1145/2733373.2806352.
3.Ellis, D. P. W., & Lee, K. (2004). Features and Classifiers for the Detection of Human Distress Sounds. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 485-488.




